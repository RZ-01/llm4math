Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████| 8/8 [00:16<00:00,  2.05s/it]
INFO:__main__:Tokenizer max length: 1000000000000000019884624838656
INFO:__main__:Loading datasets...
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    main(args)
  File "train.py", line 37, in main
    train_dataset, val_dataset = load_train_val_datasets(
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/data/dataset_loader.py", line 27, in load_train_val_datasets
    verify_data = prepare_dataset(verify_data, "train")
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/data/dataset_loader.py", line 16, in prepare_dataset
    prompts = [generate_prompt_fn(data_point) for data_point in dataset]
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/data/dataset_loader.py", line 16, in <listcomp>
    prompts = [generate_prompt_fn(data_point) for data_point in dataset]
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/data/utils.py", line 8, in generate_prompt
    text = f"""<start_of_turn>user {prefix_text} {data_point["prompt"]} <end_of_turn>\\n<start_of_turn>model{data_point["completion"]} <end_of_turn>"""
KeyError: 'completion'
