2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_setup.py:_flush():68] Current SDK version is 0.19.0
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_setup.py:_flush():68] Configure stats pid to 158738
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_setup.py:_flush():68] Loading settings from /home/llm4math/.config/wandb/settings
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_setup.py:_flush():68] Loading settings from /home/llm4math/LLM-for-Math/Direct Verifier/code/wandb/settings
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_setup.py:_flush():68] Loading settings from environment variables
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_init.py:_log_setup():528] Logging user logs to /home/llm4math/LLM-for-Math/Direct Verifier/code/wandb/run-20241210_230721-wzq1n59m/logs/debug.log
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_init.py:_log_setup():529] Logging internal logs to /home/llm4math/LLM-for-Math/Direct Verifier/code/wandb/run-20241210_230721-wzq1n59m/logs/debug-internal.log
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_init.py:init():639] calling init triggers
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_init.py:init():645] wandb.init called with sweep_config: {}
config: {'mode': 'inference', 'model_id': 'google/gemma-2-9b', 'model_path': '/media/hdd/llm4math/checkpoint-12261/', 'test_data_path': '../../inference_results.jsonl', 'output_path': './inference_results.jsonl', 'project_name': 'gemma_inference_project', 'run_name': 'gemma_inference_run', 'num_votes': 5, 'batch_size': 8}
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_init.py:init():688] starting backend
2024-12-10 23:07:21,105 INFO    MainThread:158738 [wandb_init.py:init():692] sending inform_init request
2024-12-10 23:07:21,109 INFO    MainThread:158738 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-12-10 23:07:21,109 INFO    MainThread:158738 [wandb_init.py:init():705] backend started and connected
2024-12-10 23:07:21,110 INFO    MainThread:158738 [wandb_init.py:init():798] updated telemetry
2024-12-10 23:07:21,114 INFO    MainThread:158738 [wandb_init.py:init():830] communicating run to backend with 90.0 second timeout
2024-12-10 23:07:21,482 INFO    MainThread:158738 [wandb_init.py:init():882] starting run threads in backend
2024-12-10 23:07:21,584 INFO    MainThread:158738 [wandb_run.py:_console_start():2443] atexit reg
2024-12-10 23:07:21,584 INFO    MainThread:158738 [wandb_run.py:_redirect():2293] redirect: wrap_raw
2024-12-10 23:07:21,584 INFO    MainThread:158738 [wandb_run.py:_redirect():2358] Wrapping output streams.
2024-12-10 23:07:21,584 INFO    MainThread:158738 [wandb_run.py:_redirect():2383] Redirects installed.
2024-12-10 23:07:21,585 INFO    MainThread:158738 [wandb_init.py:init():925] run started, returning control to user process
2024-12-10 23:07:48,558 INFO    MainThread:158738 [wandb_run.py:_finish():2169] finishing run sg151921942-massachusetts-institute-of-technology/gemma_inference_project/wzq1n59m
2024-12-10 23:07:48,559 INFO    MainThread:158738 [wandb_run.py:_atexit_cleanup():2408] got exitcode: 0
2024-12-10 23:07:48,559 INFO    MainThread:158738 [wandb_run.py:_restore():2390] restore
2024-12-10 23:07:48,559 INFO    MainThread:158738 [wandb_run.py:_restore():2396] restore done
2024-12-10 23:07:50,251 INFO    MainThread:158738 [wandb_run.py:_footer_history_summary_info():3951] rendering history
2024-12-10 23:07:50,251 INFO    MainThread:158738 [wandb_run.py:_footer_history_summary_info():3983] rendering summary
2024-12-10 23:07:50,255 INFO    MainThread:158738 [wandb_run.py:_footer_sync_info():3912] logging synced files
