INFO:__main__:Loading model from /media/hdd/llm4math/checkpoint-12261/
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.17it/s]
Traceback (most recent call last):
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/infer.py", line 115, in <module>
    main(args)
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/infer.py", line 66, in main
    model, tokenizer = load_model_and_tokenizer(args.model_path, device)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/infer.py", line 21, in load_model_and_tokenizer
    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/transformers/modeling_utils.py", line 3157, in to
    return super().to(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1340, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 962, in _apply
    if param_grad is not None:
       ^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
