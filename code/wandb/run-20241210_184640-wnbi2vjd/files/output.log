Loading checkpoint shards: 100%|██████████████████| 8/8 [00:15<00:00,  1.99s/it]
INFO:__main__:Tokenizer max length: 1000000000000000019884624838656
INFO:__main__:Loading datasets...
INFO:__main__:Train dataset length: 7473
INFO:__main__:Validation dataset length: 1319
Traceback (most recent call last):
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/train.py", line 82, in <module>
    main(args)
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/train.py", line 48, in main
    trainable, total = model.get_nb_trainable_parameters()
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1931, in __getattr__
    raise AttributeError(
AttributeError: 'Gemma2ForCausalLM' object has no attribute 'get_nb_trainable_parameters'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/llm4math/LLM-for-Math/Direct Verifier/code/train.py", line 82, in <module>
[rank1]:     main(args)
[rank1]:   File "/home/llm4math/LLM-for-Math/Direct Verifier/code/train.py", line 48, in main
[rank1]:     trainable, total = model.get_nb_trainable_parameters()
[rank1]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1931, in __getattr__
[rank1]:     raise AttributeError(
[rank1]: AttributeError: 'Gemma2ForCausalLM' object has no attribute 'get_nb_trainable_parameters'
