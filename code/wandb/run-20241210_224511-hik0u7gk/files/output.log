INFO:__main__:Loading model from /media/hdd/llm4math/checkpoint-12261/
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.17it/s]
Traceback (most recent call last):
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/infer.py", line 115, in <module>
    main(args)
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/infer.py", line 66, in main
    model, tokenizer = load_model_and_tokenizer(args.model_path, device)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/LLM-for-Math/Direct Verifier/code/infer.py", line 21, in load_model_and_tokenizer
    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4310, in from_pretrained
    model.load_adapter(
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/transformers/integrations/peft.py", line 214, in load_adapter
    inject_adapter_in_model(peft_config, self, adapter_name, **peft_load_kwargs)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/mapping.py", line 260, in inject_adapter_in_model
    peft_model = tuner_cls(model, peft_config, adapter_name=adapter_name, low_cpu_mem_usage=low_cpu_mem_usage)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/model.py", line 141, in __init__
    super().__init__(model, config, adapter_name, low_cpu_mem_usage=low_cpu_mem_usage)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/tuners_utils.py", line 184, in __init__
    self.inject_adapter(self.model, adapter_name, low_cpu_mem_usage=low_cpu_mem_usage)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/tuners_utils.py", line 501, in inject_adapter
    self._create_and_replace(peft_config, adapter_name, target, target_name, parent, current_key=key)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/model.py", line 235, in _create_and_replace
    new_module = self._create_new_module(lora_config, adapter_name, target, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/model.py", line 354, in _create_new_module
    new_module = dispatcher(target, adapter_name, lora_config=lora_config, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/layer.py", line 1261, in dispatch_default
    new_module = Linear(target, adapter_name, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/layer.py", line 440, in __init__
    self.update_layer(
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/layer.py", line 152, in update_layer
    self.reset_lora_parameters(adapter_name, init_lora_weights)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/peft/tuners/lora/layer.py", line 177, in reset_lora_parameters
    nn.init.zeros_(self.lora_B[adapter_name].weight)
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/init.py", line 268, in zeros_
    return _no_grad_zero_(tensor)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/llm4math/miniconda3/envs/mathllm/lib/python3.12/site-packages/torch/nn/init.py", line 69, in _no_grad_zero_
    return tensor.zero_()
           ^^^^^^^^^^^^^^
KeyboardInterrupt
